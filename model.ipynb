{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTModel\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from transformers import ViTModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Model: Hybrid EfficientNet + ViT\n",
    "class HybridEfficientNetViT(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.3):\n",
    "        super(HybridEfficientNetViT, self).__init__()\n",
    "        self.effnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        self.effnet_features = self.effnet.features\n",
    "        self.effnet_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\", add_pooling_layer=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(1280 + 768, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = next(self.parameters()).device\n",
    "        x = x.to(device)\n",
    "        \n",
    "        effnet_features = self.effnet_features(x)\n",
    "        effnet_features = self.effnet_avgpool(effnet_features)\n",
    "        effnet_features = torch.flatten(effnet_features, 1)\n",
    "        \n",
    "        vit_outputs = self.vit(pixel_values=x).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        combined_features = torch.cat((effnet_features, vit_outputs), dim=1)\n",
    "        x = self.bn1(F.relu(self.fc1(combined_features)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-4, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_acc = 0.0\n",
    "    best_model_path = \"best_hybrid_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "        acc = evaluate_model(model, val_loader, device)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"Best model saved!\")\n",
    "    \n",
    "    torch.save(model.state_dict(), \"hybrid_model.pth\")\n",
    "    torch.save(model, \"hybrid_model_full.pth\")\n",
    "    print(\"Final model saved successfully!\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Dataset Path\n",
    "DATASET_PATH = r\"/content/drive/MyDrive/hackathone/Diabetic_Balanced_Data\"\n",
    "\n",
    "# Custom PyTorch Dataset\n",
    "class DiabeticRetinopathyDataset(Dataset):\n",
    "    def __init__(self, base_path, transform=None):\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_label in range(5):  # Classes: 0, 1, 2, 3, 4\n",
    "            folder_path = os.path.join(base_path, str(class_label))\n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"Warning: Folder {folder_path} not found!\")\n",
    "                continue\n",
    "            \n",
    "            for img_name in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(class_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Creating DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = DiabeticRetinopathyDataset(os.path.join(DATASET_PATH, \"train\"), transform=transform)\n",
    "val_dataset = DiabeticRetinopathyDataset(os.path.join(DATASET_PATH, \"val\"), transform=transform)\n",
    "test_dataset = DiabeticRetinopathyDataset(os.path.join(DATASET_PATH, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = HybridEfficientNetViT(num_classes=5, dropout_rate=0.3)\n",
    "train_model(model, train_loader, val_loader, epochs=10, lr=1e-4, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model_path=\"hybrid_model.pth\", device=\"cuda\"):\n",
    "    model = HybridEfficientNetViT(num_classes=5)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on test dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "acc, f1, precision, recall = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
